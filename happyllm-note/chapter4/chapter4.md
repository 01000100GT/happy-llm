# 第四章课后习题

## 选择题

### 1. 一般认为，以下哪个模型是 LLM 的开端？（ ）

A. BERT

B. GPT - 3

C. ChatGPT

D. LLaMA

答案：B

### 2. LLM 具备的涌现能力类似于物理学中的哪种现象？（ ）


A. 折射现象

B. 反射现象

C. 相变现象

D. 电磁感应现象

答案：C
解析：可以类比到物理学中的相变现象，**涌现能力**的显现就像是模型性能随着规模增大而迅速提升，超过了随机水平，也就是我们常说的量变引起了质变

### 3. 上下文学习能力是由哪个模型首次引入的？（ ）

A. BERT

B. GPT - 3

C. ChatGPT

D. T5

答案：B

### 4. 以下哪种能力不是 LLM 区别于传统 PLM 的重要优势？（ ）

A. 涌现能力

B. 上下文学习能力

C. 图像识别能力

D. 逐步推理能力

答案：C


### 5. 训练 LLM 的预训练任务通常是（ ）。

A. 因果语言模型（CLM）

B. 掩码语言模型（MLM）

C. 序列到序列模型（Seq2Seq）

D. 卷积神经网络（CNN）

答案：A


### 6. 以下哪个分布式训练框架使用面最广？（ ）

A. Deepspeed

B. Megatron - LM

C. ColossalAI

D. TensorFlow

答案：A

### 7. 在 SFT 阶段，指令数据集一般包含以下哪些键？（多选）（ ）

A. instruction

B. input

C. output

D. label

答案：ABC

### 8. RLHF 是指（ ）。

A. 随机梯度下降法

B. 人类反馈强化学习

C. 监督学习

D. 无监督学习

答案：B

### 9. 以下哪个模型在中文环境上可能展现更优越的效果？（ ）

A. GPT - 4

B. 文心一言

C. Google - Bard

D. Anthropic - Claude

答案：B

### 10. LLM 的预训练数据处理一般不包括以下哪个流程？（ ）

A. 文档准备

B. 语料过滤

C. 模型训练

D. 语料去重

答案：C

## 简答题

1. **请简述大语言模型（LLM）的定义及与传统预训练语言模型（PLM）的核心差异。**

答：LLM 是一种相较传统语言模型参数量更多、在更大规模语料上进行预训练的语言模型。一般来说，LLM 指包含数百亿（或更多）参数的语言模型，它们往往在数 T token 语料上通过多卡分布式集群进行预训练。与传统 PLM 的核心差异在于参数量更庞大、预训练语料更海量，从而展现出与传统预训练语言模型截然不同的能力，如具备涌现能力等。

2. **列举 LLM 的四种核心能力，并简要说明每种能力的含义。**

答：LLM 的四种核心能力分别为：

**1.** 涌现能力：同样的模型架构与预训练任务下，某些能力在小型模型中不明显，但在大型模型中特别突出，表现为模型性能随规模增大迅速提升，超过随机水平。

**2.**上下文学习：允许语言模型在提供自然语言指令或多个任务示例的情况下，通过理解上下文并生成相应输出的方式来执行任务，无需额外的训练或参数更新。

**3.**指令遵循：经过指令微调的 LLM 能够理解并遵循未见过的指令，并根据任务指令执行任务，无需事先见过具体示例，展示了强大的泛化能力。

**4.**逐步推理：LLM 通过采用思维链推理策略，利用包含中间推理步骤的提示机制来解决涉及多个推理步骤的复杂任务，得出最终答案。

3. **训练一个完整的 LLM 需要经过哪三个阶段？并简要说明每个阶段的主要任务。**

答：训练完整的 LLM 需要经过 Pretrain、SFT 和 RLHF 三个阶段。

**1.** Pretrain（预训练）：使用海量无监督文本对随机初始化的模型参数进行训练，目前主流的 LLM 几乎都采用 Decoder - Only 的类 GPT 架构，预训练任务为因果语言模型（CLM），此阶段核心在于庞大的参数量和海量的预训练语料。

**2.** SFT（有监督微调）：通过指令微调的方式，训练模型的 “通用指令遵循能力”，输入是各种类型的用户指令，让模型拟合希望的回复，使模型能够理解并回复用户的指令。

**3.** RLHF（人类反馈强化学习）：引入强化学习技术，通过实时的人类反馈令 LLM 能够给出更令人类满意的回复，让 LLM 和人类价值观对齐，达到安全、有用、无害的标准。

4. **预训练 LLM 时，数据并行和模型并行的核心思路分别是什么？**

答：数据并行的核心思路是，虽然训练模型的尺寸可以被单个 GPU 内存容纳，但增大训练的 batch_size 会增大显存开销，让模型实例在不同 GPU 和不同批数据上运行，每一次前向传递完成之后，收集所有实例的梯度并进行梯度更新。更新模型参数之后，再传递到所有实例当中，使得每张 GPU 上的模型参数保持一致，此时，训练的总批次大小就等于每张卡上的批次大小之和。

模型并行的核心思路是，当 LLM 扩大到上百亿参数，单张 GPU 内存无法存放完整的模型参数时，将模型拆分到多个 GPU 上，每个 GPU 上存放不同的层或不同的部分。

5. **在 SFT 阶段，如何构造多轮对话样本？哪种方式最合理，为什么？**

答：在 SFT 阶段，构造多轮对话样本一般有三种方式：

**1.** 直接将最后一次模型回复作为输出，前面所有历史对话作为输入，直接拟合最后一次回复。

**2.** 将 N 轮对话构造成 N 个样本。

**3.** 直接要求模型预测每一轮对话的输出。其中，第三种方式最合理。因为 LLM 本质还是进行的 CLM 任务，进行单向注意力计算，在预测时会从左到右依次进行拟合，前轮的输出预测不会影响后轮的预测，而第一种方式会丢失大量中间信息，第二种方式造成了大量重复计算。