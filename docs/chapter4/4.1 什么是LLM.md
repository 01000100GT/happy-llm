# 4.1 什么是 LLM

在前三章，我们从 NLP 的定义与主要任务出发，介绍了引发 NLP 领域重大变革的核心思想——注意力机制与 Transformer 架构。
随着 Transformer 架构的横空出世，NLP 领域逐步进入预训练-微调范式，
以 Transformer 为基础的、通过预训练获得强大文本表示能力的预训练语言模型
层出不穷，将 NLP 的各种经典任务都推进到了一个新的高度。

随着2022年底 ChatGPT 再一次刷新 NLP 的能力上限，LLM（大模型）开始接替传统的 PLM 成为 NLP 的主流方向，
基于 LLM 的全新研究范式也正在刷新被 BERT 发扬光大的预训练-微调范式，NLP 由此迎来又一次翻天覆地的变化。
从2022年底至今，LLM 能力上限不断刷新，通用基座大模型数量指数级上升，基于 LLM 的概念、应用也是日新月异，预示着大模型时代的到来。

在第三章，我们从模型架构的角度出发，分别分析了 Encoder-Only、Encoder-Decoder 和 Decoder-Only 三种架构下的经典模型及其训练过程。
这些模型有的是 LLM 时代之前堪称时代主角的里程碑（如 BERT），有的则是 LLM 时代的舞台主角，是 AGI（通用人工智能） 的有力竞争者。
那么，究竟什么是 LLM，LLM 和传统的 PLM 的核心差异在哪里，又是什么令研究者们对 LLM 抱有如此高的热情与期待呢？

在本章中，我们将结合上文的模型架构讲解，深入分析 LLM 的定义、特点及其能力，为读者揭示 LLM 与传统深度学习模型的核心差异，
并在此基础上，展示 LLM 的实际三阶段训练过程，帮助读者从概念上厘清 LLM 是如何获得这样的独特能力的，
从而为进一步实践 LLM 完整训练提供理论基础。

## 4.1.1 LLM 的定义

LLM，即 Large Language Model，中文名为大语言模型或大型语言模型，
是一种相较传统语言模型参数量更多、在更大规模语料上进行预训练的语言模型。

在第一章中，我们已经介绍了语言模型（LM）的概念，即通过预测下一个 token 任务来训练的 NLP 模型。
LLM 使用与传统预训练语言模型相似的架构与预训练任务（如 Decoder-Only 架构与 CLM 预训练任务），
但拥有更庞大的参数、在更海量的语料上进行预训练，也从而展现出与传统预训练语言模型截然不同的能力。

一般来说，LLM 指包含**数百亿（或更多）参数的语言模型**，它们往往在**数 T token 语料上**通过多卡分布式集群进行预训练，
具备远超出传统预训练模型的文本理解与生成能力。不过，随着 LLM 研究的不断深入，多种参数尺寸的 LLM 逐渐丰富，
广义的 LLM 一般覆盖了从**十亿参数**（如 Qwen-1.5B）到**千亿参数**（如 Grok-314B）的所有大型语言模型。
只要模型展现出**涌现能力**，即在一系列复杂任务上表现出远超传统预训练模型（如 BERT、T5）的能力与潜力，都可以称之为 LLM。

一般认为，GPT-3（1750亿参数）是 LLM 的开端，
基于 GPT-3 通过 Pretrain、SFT、RLHF 三阶段训练得到的 ChatGPT 更是主导了 LLM 时代的到来。
自2022年11月 OpenAI 发布 ChatGPT 至今不到2年时间里，已涌现出了上百个各具特色、能力不一的 LLM。
下表列举了自 2022年11月至2023年11月国内外发布的部分大模型：

时间     | 开源 LLM                                       | 闭源 LLM
-------- | -----                                         | --------
2023.11  | 无                                            | OpenAI-ChatGPT
2023.02  | Meta-LLaMA；复旦-MOSS                         | 无
2023.03  | 斯坦福-Alpaca、Vicuna；智谱-ChatGLM|OpenAI-GPT4；百度-文心一言；Anthropic-Claude；Google-Bard
2023.04  | 阿里-通义千问；Stability AI-StableLM|商汤-日日新
2023.05  | 微软-Pi；Tll-Falcon|讯飞-星火大模型；Google-PaLM2
2023.06  | 智谱-ChatGLM2；上海 AI Lab-书生浦语；百川-BaiChuan；虎博-TigerBot|360-智脑大模型
2023.07  | Meta-LLaMA2|Anthropic-Claude2；华为-盘古大模型3
2023.08  | 无|字节-豆包
2023.09  | 百川-BaiChuan2|Google-Gemini；腾讯-混元大模型
2023.11  | 零一万物-Yi；幻方-DeepSpeek|xAI-Grok

目前，国内外企业、研究院正不断推出性能更强大的 LLM，探索通往 AGI 的道路。

## 4.1.2 LLM 的能力

### 1. 涌现能力（Emergent Abilities）

区分 LLM 与传统 PLM 最显著的特征即是 LLM 具备 `涌现能力` 。
涌现能力是指同样的模型架构与预训练任务下，某些能力在小型模型中不明显，但在大型模型中特别突出。
可以类比到物理学中的相变现象，涌现能力的显现就像是模型性能随着规模增大而迅速提升，超过了随机水平，也就是我们常说的量变引起了质变。

具体来说，涌现能力可以定义为与某些复杂任务相关的能力。
但一般而言，NLP 更关注的是它们具备的通用能力，也就是能够应用于解决各种 NLP 任务的能力。
涌现能力是目前业界和学界对 LLM 保持较高的热情和关注的核心所在，
即虽然 LLM 目前的能力、所能解决的任务与人类最终所期待的通用人工智能还存在不小的差距，
但在涌现能力的作用下，我们相信随着研究的不断深入、高质量数据的不断涌现和更高效的模型架构及训练框架的出现，
LLM 终能具备通用人工智能所需要具备的能力，从而给人类生活带来质变。

### 2. 上下文学习（In-context Learning）

上下文学习能力是由 GPT-3 首次引入的。
具体而言，上下文学习是指允许语言模型在提供自然语言指令或多个任务示例的情况下，
通过理解上下文并生成相应输出的方式来执行任务，而无需额外的训练或参数更新。

对传统 PLM，在经过高成本的预训练之后，往往还需要对指定的下游任务进行有监督微调。
虽然传统 PLM 体量较小，对算力要求较低，但例如 BERT 类模型（0.5B 参数），进行有监督微调一般还是需要 10G 以上显存，有一定的算力成本。
而同时，有监督微调的训练数据的成本更高。针对下游任务难度的不同，需要的训练样本数往往在 1k~数十k 不等，
均需要进行人工标注，数据获取上有不小的成本。
而具备上下文学习能力的 LLM 往往无需进行高成本的额外训练或微调，而可以通过少数示例或是调整自然语言指令，
来处理绝大部分任务，从而大大节省了算力和数据成本。

上下文学习能力也正在引发 NLP 研究范式的变革。在传统 PLM 时代，解决 NLP 下游任务的一般范式是预训练-微调，
即选用一个合适的预训练模型，针对自己的下游任务准备有监督数据来进行微调。
而通过使用具备上下文学习能力的 LLM，一般范式开始向 Prompt Engineering 也就是调整 Prompt 来激发 LLM 的能力转变。
例如，目前绝大部分 NLP 任务，通过调整 Prompt 或提供 1~5 个自然语言示例，就可以令 GPT-4 达到超过传统 PLM 微调的效果。

### 3. 指令遵循（Instruction Following）

通过使用自然语言描述的多任务数据进行微调，也就是所谓的 `指令微调` ，
LLM 被证明在同样使用指令形式化描述的未见过的任务上表现良好。
也就是说，经过指令微调的 LLM 能够理解并遵循未见过的指令，并根据任务指令执行任务，
而无需事先见过具体示例，这展示了其强大的泛化能力。

指令遵循能力意味我们不再需要每一件事都先教模型，然后它才能去做。
我们只需要在指令微调阶段混合多种指令来训练其泛化能力，LLM 就可以处理人类绝大部分指令，即可以灵活地解决用户遇到的问题。
这一点在 ChatGPT 上体现地尤为明显。ChatGPT 之所以能够具备极高的热度，其核心原因即在于其不再是仅能用于学界、业界研究的理论模型，
而同样可以广泛地服务于各行各业用户。通过给 ChatGPT 输入指令，其可以写作文、编程序、批改试卷、阅读报纸......

指令遵循能力使 LLM 可以真正和多个行业结合起来，通过人工智能技术为人类生活的方方面面赋能，
从而为人类带来质的改变。不管是目前大火的 Agent、Flow，还是并不遥远的未来可能就会出现的全能助理、超级智能，
其本质依赖的都是 LLM 的指令遵循能力。

### 4. 逐步推理（Step by Step Reasoning）

逻辑推理，尤其是涉及多个推理步骤的复杂推理任务，一直是 NLP 的攻关难点，
也是人工智能难以得到普遍认可的重要原因。
毕竟，如果一个模型不能解答基础的“鸡兔同笼”问题，或者不能识别语言中的逻辑陷阱，
你很难认为它是“智能的”而非“智障的”。

但是，传统的 NLP 模型通常难以解决涉及多个推理步骤的复杂任务，例如数学问题。
然而，LLM 通过采用 `思维链（CoT, Chain of Thought）` 推理策略，
可以利用包含中间推理步骤的提示机制来解决这些任务，从而得出最终答案。
据推测，这种能力可能是通过对代码的训练获得的。

逐步推理能力意味着 LLM 可以处理复杂逻辑任务，也就是说可以解决日常生活中需要逻辑判断的绝大部分问题，
从而向“可靠的”智能助理迈出了坚实的一步。

这些独特能力是 LLM 区别于传统 PLM 的重要优势，也让 LLM 在处理各种任务时表现出色，使它们成为了解决复杂问题和应用于多领域的强大工具。
正是因为涌现能力、上下文学习能力、指令遵循能力与逐步推理能力的存在，NLP 研究人员相信 LLM 是迈向通用人工智能，
帮助人类社会实现生产力质变的重要途径。而事实上，目前已有众多基于 LLM 的应用，旨在利用 LLM 的独特能力显著提高生产力。
例如，微软基于 GPT-4 推出的 Copilot，就基于 LLM 强大的指令遵循能力与逐步推理能力，
通过提供代码补全、代码提示、代码编写等多种功能，辅助程序员更高效、便捷、精准地编写程序，极大提高了程序员的生产效率。

## 4.1.3 LLM 的特点

除上文讨论的 LLM 的核心能力外，LLM 还具备一些额外的、有趣或是危险的特点，
这些特点也是 LLM 目前重要的研究方向，在此讨论其中一二：

### 1. 多语言支持

多语言、跨语言模型曾经是 NLP 的一个重要研究方向，
但 LLM 由于需要使用到海量的语料进行预训练，训练语料往往本身就是多语言的，
因此 LLM 天生即具有多语言、跨语言能力，只不过随着训练语料和指令微调的差异，在不同语言上的能力有所差异。
由于英文高质量语料目前仍是占据大部分，以 GPT-4 为代表的绝大部分模型在英文上具有显著超越中文的能力。
虽然都可以对多种语言进行处理，但针对中文进行额外训练和优化的国内模型（如文心一言、通义千问等）往往能够在中文环境上展现更优越的效果。

### 2. 长文本处理

由于能够处理多长的上下文文本，在一定程度上决定了模型的部分能力上限，LLM 往往比传统 PLM 更看重长文本处理能力。
相对于以 512 token 为惯例的传统 PLM（如 BERT、T5等模型的最大上下文长度均为 512），
LLM 在拓宽最大上下文长度方面可谓妙计频出。
由于在海量分布式训练集群上进行训练，LLM 往往在训练时就支持 4k、8k 甚至 32k 的上下文长度。
同时，LLM 大部分采用了 RoPE （或者同样具有外推能力的 AliBi）作为位置编码，具有一定的长度外推能力，
也就是在推理时能够处理显著长于训练长度的文本。
例如，InternLM 在 32k 长度上下文上进行了预训练，但通过 RoPE 能够实现 200k 长度的上下文处理。
通过不断增强长文本处理能力，LLM 往往能够具备更强的信息阅读、信息总结能力，
从而解决诸如要求 LLM 读完《红楼梦》并写一篇对应的高考作文的“世纪难题”。

### 3. 拓展多模态

LLM 的强大能力也为其带来了跨模态的强大表现。随着 LLM 的不断改进，通过为 LLM 增加额外的参数来进行图像表示，
从而利用 LLM 的强大能力打造支持文字、图像双模态的模型，已经是一个成功的方法。通过引入 Adapter 层和图像编码器，
并针对性地在图文数据上进行有监督微调，模型能够具备不错的图文问答甚至生成能力。在未来，如何对齐文本与图像的表示，
从而打造更强大的多模态大模型，将 LLM 的能力辐射到更多模态，是一个重要的研究方向。

### 4. 挥之不去的幻觉

幻觉，是指 LLM 根据 Prompt 杜撰生成虚假、错误信息的表现。例如，当我们要求 LLM 生成一篇学术论文及其参考文献列表时，
其往往会捏造众多看似“一本正经”实则完全不存在的论文和研究。幻觉问题是 LLM 的固有缺陷，也是目前 LLM 研究及应用的巨大挑战。
尤其是在医学、金融学等非常强调精准、正确的领域，幻觉的存在可能造成非常严重的后果。
目前也有很多研究提供了削弱幻觉的一些方法，如 Prompt 里进行限制、通过 RAG（检索增强生成）来指导生成等，
但都还只能一定程度减弱幻觉而无法彻底根除。

除上述几点之外，LLM 还存在诸多可供研究的特点，例如我们将在下一节详细论述的 LLM 三阶段训练流程、LLM 的自我反思性等，
此处就不一一列举赘述了。

**参考文献**

1. [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)